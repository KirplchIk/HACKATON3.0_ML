# person_detector_hog_svm/src/training.py

import numpy as np                     # NumPy для работы с массивами данных (признаки, метки)
from sklearn.svm import LinearSVC      # Сам линейный SVM классификатор из scikit-learn
from sklearn.model_selection import train_test_split # Функция для разделения данных на обучение и тест
from sklearn.metrics import classification_report, accuracy_score # Метрики для оценки качества модели
import joblib                          # Для сохранения и загрузки обученной модели (эффективнее для numpy-based моделей, чем pickle)
import time                            # Для замера времени обучения
import os                              # Для проверки существования файлов
import sys                             # Для настройки путей импорта

# Снова магия с путями, чтобы найти наши модули
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# Импортируем наш конфиг, где лежат пути и параметры SVM
# Импорт data_preparation здесь был, видимо, по ошибке копирования, убираем, т.к. не используется
# from src import data_preparation # <-- Не используется в этом файле
from src import config                 # Загружаем пути и параметры

def train_svm_model(features_path, labels_path, model_save_path, svm_c, svm_dual):
    """
    Основная функция обучения. Загружает HOG-признаки и метки,
    разделяет их на обучающую и тестовую выборки, обучает модель LinearSVC,
    оценивает её качество на тесте и сохраняет обученную модель.

    Args:
        features_path (str): Путь к файлу .npy с матрицей признаков (HOG-векторы).
        labels_path (str): Путь к файлу .npy с вектором меток (0 или 1).
        model_save_path (str): Куда сохранить обученную модель (файл .joblib).
        svm_c (float): Параметр регуляризации C для LinearSVC. Влияет на "штраф" за ошибки.
        svm_dual (str or bool): Параметр dual для LinearSVC ('auto', True, False). Влияет на алгоритм оптимизации.
    """
    print("Начинаем процесс обучения SVM модели...")

    # --- Шаг 1: Загрузка данных ---
    # Прежде чем что-то делать, проверим, есть ли вообще файлы с данными
    if not os.path.exists(features_path):
        print(f"Ошибка: Файл с признаками не найден: {features_path}")
        print("Убедитесь, что скрипт feature_extraction.py отработал успешно.")
        return # Прекращаем работу
    if not os.path.exists(labels_path):
        print(f"Ошибка: Файл с метками не найден: {labels_path}")
        return # Прекращаем работу

    # Загружаем признаки (X) и метки (y) из .npy файлов
    print("Загружаем признаки и метки из файлов...")
    try:
        X = np.load(features_path) # Матрица признаков
        y = np.load(labels_path)   # Вектор меток
        print(f"Загружено: {X.shape[0]} сэмплов, {X.shape[1]} признаков в каждом.")
    except Exception as e:
        print(f"Ошибка при загрузке данных из .npy файлов: {e}")
        return # Прекращаем работу

    # Проверяем консистентность данных
    if X.shape[0] == 0 or y.shape[0] == 0:
        print("Ошибка: Загруженные данные пусты.")
        return
    if X.shape[0] != y.shape[0]:
        print(f"Ошибка: Количество признаков ({X.shape[0]}) не совпадает с количеством меток ({y.shape[0]}).")
        return

    # --- Шаг 2: Разделение данных ---
    # Делим наши данные на две части:
    # 1. Обучающая выборка (X_train, y_train): на ней модель будет учиться.
    # 2. Тестовая выборка (X_test, y_test): на ней мы проверим, как хорошо модель выучилась.
    #    Эта выборка моделью во время обучения "не видна".
    print("Разделяем данные на обучающую (80%) и тестовую (20%) выборки...")
    try:
        # test_size=0.2 означает, что 20% данных уйдет в тест, 80% - в обучение.
        # random_state=42 гарантирует, что разделение будет всегда одинаковым при повторных запусках (для воспроизводимости).
        # stratify=y - ОЧЕНЬ ВАЖНО! Гарантирует, что пропорция классов (люди/фон) будет одинаковой
        #              и в обучающей, и в тестовой выборках. Это критично для несбалансированных данных.
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        print(f"Размер обучающей выборки: {X_train.shape[0]} сэмплов.")
        print(f"Размер тестовой выборки: {X_test.shape[0]} сэмплов.")
    except ValueError as e:
        # Ошибка ValueError может возникнуть, если в одном из классов слишком мало примеров для стратификации.
        print(f"Предупреждение: Не удалось выполнить стратифицированное разделение (возможно, мало данных одного из классов). Ошибка: {e}")
        print("Выполняем обычное разделение без стратификации.")
        # В этом случае делаем обычное разделение, но пропорции классов могут "поплыть".
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

    # --- Шаг 3: Инициализация и Обучение Модели ---
    # Используем LinearSVC - линейный SVM, который хорошо подходит для задач с большим
    # количеством признаков (как у нас после HOG) и часто работает быстрее,
    # чем обычный SVC с линейным ядром (`SVC(kernel='linear')`).

    print(f"Инициализируем модель LinearSVC с параметрами: C={svm_c}, dual={svm_dual}...")
    # C - параметр регуляризации. Чем он меньше, тем "проще" модель (больше обобщение, но может недообучиться).
    #         Чем больше C, тем точнее модель подгоняется под обучающие данные (риск переобучения).
    # dual='auto' - scikit-learn сам выберет оптимальный алгоритм решения ( primal или dual).
    #         Обычно выбирается dual=False, если сэмплов больше, чем признаков (что обычно быстрее).
    # max_iter - максимальное число итераций для сходимости алгоритма. Увеличили на всякий случай.
    # tol - порог для остановки оптимизации.
    model = LinearSVC(C=svm_c, random_state=42, tol=1e-4, max_iter=5000, dual=svm_dual)

    # Обучаем модель на обучающей выборке
    print("Запускаем обучение модели SVM...")
    start_time = time.time() # Засекаем время
    try:
        # Метод `fit` - это и есть процесс обучения. Модель ищет оптимальную гиперплоскость.
        model.fit(X_train, y_train)
        end_time = time.time()
        print(f"Обучение модели завершено за {end_time - start_time:.2f} сек.")
    except Exception as e:
        # Если во время обучения произошла ошибка
        print(f"Ошибка в процессе обучения модели: {e}")
        import traceback
        traceback.print_exc() # Печатаем детали ошибки
        return # Прерываем работу

    # --- Шаг 4: Оценка Модели ---
    # Проверяем, как хорошо наша обученная модель работает на данных, которые она НЕ видела (тестовая выборка).
    print("Оцениваем качество модели на тестовой выборке...")
    try:
        # Получаем предсказания модели для тестовых признаков
        y_pred = model.predict(X_test)
        # Считаем общую точность (accuracy) - долю правильных ответов
        accuracy = accuracy_score(y_test, y_pred)
        # Генерируем подробный отчет: точность (precision), полнота (recall), F1-мера для каждого класса
        # target_names=['background', 'person'] - задаем имена для классов 0 и 1 для читаемости отчета
        report = classification_report(y_test, y_pred, target_names=['background', 'person'])

        # Выводим результаты оценки
        print("-" * 30)
        print("Результаты оценки на тестовом наборе:")
        print(f"Общая точность (Accuracy): {accuracy:.4f}")
        print("Детальный отчет (Classification Report):")
        print(report)
        # Анализ отчета:
        # - Precision (точность) для 'person': Какая доля из тех, кого модель назвала 'person', действительно ими являются?
        # - Recall (полнота) для 'person': Какую долю реальных 'person' модель смогла найти?
        # - F1-score: Гармоническое среднее между precision и recall.
        # - Support: Количество примеров каждого класса в тестовой выборке.
        print("-" * 30)
    except Exception as e:
        # Если ошибка во время оценки (маловероятно, но возможно)
        print(f"Ошибка при оценке модели: {e}")
        # Оценку провести не удалось, но модель все равно сохраним ниже.

    # --- Шаг 5: Сохранение Модели ---
    # Сохраняем обученную модель в файл, чтобы потом использовать ее для детекции.
    print(f"Сохраняем обученную модель в файл: {model_save_path}...")
    try:
        # joblib.dump - хороший способ сохранять модели scikit-learn
        joblib.dump(model, model_save_path)
        print("Модель успешно сохранена.")
    except Exception as e:
        print(f"Ошибка при сохранении модели: {e}")

    print("Скрипт обучения SVM завершен.")


# ---- Блок для самостоятельного запуска ----
# Выполняется, если запустить файл напрямую: python src/training.py
if __name__ == "__main__":
    print("Запускаем training.py как основной скрипт...")
    # Вызываем нашу основную функцию обучения, передавая ей пути и параметры из конфига
    train_svm_model(
        features_path=config.FEATURES_PATH,   # Путь к .npy с признаками
        labels_path=config.LABELS_PATH,     # Путь к .npy с метками
        model_save_path=config.SVM_MODEL_PATH, # Куда сохранить модель
        svm_c=config.SVM_C,                 # Параметр C из конфига
        svm_dual=config.SVM_DUAL            # Параметр dual из конфига
    )
    print("Работа training.py завершена.")