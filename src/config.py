# person_detector_hog_svm/src/config.py
import os

# --- Основные пути ---
# Определяем корень нашего проекта.
# `__file__` - это путь к текущему файлу (config.py)
# `os.path.abspath` делает путь абсолютным
# `os.path.dirname` поднимает на один уровень вверх (из src в корень)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Папка, где лежит наш датасет (ожидаем, что он называется 'person-detection-10k')
DATA_DIR = os.path.join(BASE_DIR, 'data', 'person-detection-10k')

# Папка, куда будут складываться все результаты нашей работы
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')

# --- Пути к данным (внутри DATA_DIR) ---
# Предполагаем стандартную структуру датасета с папками train/val/test и images/labels
TRAIN_IMAGE_DIR = os.path.join(DATA_DIR, 'train', 'images') # Картинки для обучения
TRAIN_LABEL_DIR = os.path.join(DATA_DIR, 'train', 'labels') # Аннотации (YOLO) для обучения
VAL_IMAGE_DIR = os.path.join(DATA_DIR, 'val', 'images')     # Картинки для валидации (если используем)
VAL_LABEL_DIR = os.path.join(DATA_DIR, 'val', 'labels')     # Аннотации для валидации
TEST_IMAGE_DIR = os.path.join(DATA_DIR, 'test', 'images')   # Картинки для финального теста
TEST_LABEL_DIR = os.path.join(DATA_DIR, 'test', 'labels')   # Аннотации для теста

# --- Пути для вывода (внутри OUTPUT_DIR) ---
# Здесь будут лежать результаты обработки и модели

# Папка для нарезанных сэмплов
PREPARED_DATA_DIR = os.path.join(OUTPUT_DIR, 'prepared_data')
POSITIVE_SAMPLES_DIR = os.path.join(PREPARED_DATA_DIR, 'positive_samples') # Вырезанные люди
NEGATIVE_SAMPLES_DIR = os.path.join(PREPARED_DATA_DIR, 'negative_samples') # Вырезанный фон

# Папка для HOG-признаков
FEATURES_DIR = os.path.join(OUTPUT_DIR, 'features')
FEATURES_PATH = os.path.join(FEATURES_DIR, 'features.npy') # Сами признаки (большой массив)
LABELS_PATH = os.path.join(FEATURES_DIR, 'labels.npy')     # Метки к ним (0 или 1)

# Папка для обученных моделей
MODELS_DIR = os.path.join(OUTPUT_DIR, 'models')
SVM_MODEL_PATH = os.path.join(MODELS_DIR, 'svm_model.joblib') # Сохраненная SVM модель
HOG_PARAMS_JSON = os.path.join(MODELS_DIR, 'hog_params.json') # Параметры HOG, с которыми обучали

# Папка для результатов детекции (картинки с рамками)
DETECTIONS_DIR = os.path.join(OUTPUT_DIR, 'detections')

# --- Создание папок ---
# Убедимся, что все папки для вывода существуют.
# `exist_ok=True` значит, что если папка уже есть, ошибки не будет.
os.makedirs(POSITIVE_SAMPLES_DIR, exist_ok=True)
os.makedirs(NEGATIVE_SAMPLES_DIR, exist_ok=True)
os.makedirs(FEATURES_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(DETECTIONS_DIR, exist_ok=True)

# --- Параметры подготовки данных ---
# Размер окна, к которому приводим ВСЕ вырезанные сэмплы (и позитивные, и негативные).
# Это КЛЮЧЕВОЙ параметр для HOG. Классика для пешеходов - (64, 128).
# Должен быть совместим с параметрами HOG ниже (кратен cellSize и blockSize).
WINDOW_SIZE = (64, 128)

# Сколько негативных (фоновых) картинок вырезать с одного обучающего изображения.
# Больше -> разнообразнее фон, но дольше подготовка и обучение.
NEG_SAMPLES_PER_IMAGE = 3 # Раньше было 1, можно попробовать больше для лучшего обучения

# При вырезании негативных сэмплов, какой максимальный процент пересечения (IoU)
# допустим с реальным объектом (человеком) из аннотации.
# 0.1 значит, что если случайный кусок фона пересекается с человеком больше, чем на 10%,
# то мы его не берем в негативы (чтобы не путать модель).
NEG_IOU_THRESHOLD = 0.1

# --- Параметры HOG (Histogram of Oriented Gradients) ---
# Это "сердце" нашего детектора признаков. Их нужно тщательно подбирать!
# Стандартные параметры из статьи Dalal & Triggs - хорошая отправная точка.
HOG_PARAMS = {
    'winSize': WINDOW_SIZE,        # Размер окна анализа HOG - ДОЛЖЕН СОВПАДАТЬ с WINDOW_SIZE!
    'blockSize': (16, 16),         # Размер блока для нормализации контраста (в пикселях).
    'blockStride': (8, 8),         # Шаг, с которым скользит блок (в пикселях). Влияет на перекрытие блоков.
    'cellSize': (8, 8),            # Размер ячейки, внутри которой строится гистограмма градиентов.
    'nbins': 9,                    # Количество "корзин" (направлений градиента) в гистограмме (0-180 градусов).
    'derivAperture': 1,            # Апертура для оператора Собеля (редко меняют).
    'winSigma': -1.,               # Параметр Гауссова сглаживания окна перед вычислением HOG (-1 = авто).
    'histogramNormType': 0,        # Тип нормализации гистограмм в блоке (0 = L2-Hys - стандарт).
    'L2HysThreshold': 0.2,         # Порог для L2-Hys нормализации (максимальное значение после L2 нормализации).
    'gammaCorrection': True,       # Применять ли гамма-коррекцию (улучшает устойчивость к свету).
    'nlevels': 64,                 # Макс. количество уровней детекции в `detectMultiScale` (влияет на производительность).
    'signedGradients': True        # Использовать ли градиенты 0-360 градусов (True) или 0-180 (False). True обычно лучше.
}

# --- Параметры SVM (Support Vector Machine) ---
# Классификатор, который будет решать, является ли HOG-вектор человеком или нет.
SVM_C = 0.01                   # Параметр регуляризации. Маленькое C -> более "мягкая" граница, больше ошибок на обучении, но лучше обобщение (иногда). Большое C -> жесткая граница, меньше ошибок на обучении, риск переобучения. НУЖНО ПОДБИРАТЬ!
SVM_DUAL = 'auto'              # Параметр для LinearSVC. 'auto' сам выберет оптимальный алгоритм в зависимости от размера данных. Обычно хорошо работает.

# --- Параметры детекции (при запуске на новых картинках) ---
# Шаг скользящего окна в функции `detectMultiScale` (аналогично `blockStride` в HOG).
# Меньше -> медленнее, но точнее. 8 - хороший стандарт.
DETECTION_WINDOW_STEP = 6 # Логично сделать равным шагу блока HOG

# Коэффициент масштабирования пирамиды изображений.
# 1.05 - классика. Меньше -> больше уровней, медленнее, но лучше ловит разные размеры. Больше -> быстрее, но можно пропустить объекты.
DETECTION_PYRAMID_SCALE = 1.05

# Порог уверенности SVM. Все что >= этого значения - считаем человеком (до NMS).
# 0.0 - базовая линия (гиперплоскость SVM).
# Если много ложных срабатываний -> УВЕЛИЧИТЬ (например, 0.3, 0.5, 1.0).
# Если много пропусков -> УМЕНЬШИТЬ (например, -0.1), но осторожно. КЛЮЧЕВОЙ ПАРАМЕТР ДЛЯ ТЮНИНГА!
DETECTION_THRESHOLD = 0.5 # Раньше было 0.0, повысили для уменьшения ложных срабатываний (пример)

# Порог IoU для Non-Maximum Suppression. Убирает дублирующиеся рамки.
# Меньше -> агрессивнее удаляет (0.1-0.2). Больше -> позволяет большее перекрытие (0.3-0.4).
# Нужно подбирать под плотность людей на изображениях.
NMS_THRESHOLD = 0.2

# --- Класс для детекции ---
# ID класса "человек" в ваших YOLO-аннотациях.
# Убедитесь, что он совпадает с тем, что в ваших .txt файлах.
PERSON_CLASS_ID = 0